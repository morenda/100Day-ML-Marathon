{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "礙於不是所有同學都有 GPU ，這邊的範例使用的是簡化版本的 ResNet，確保所有同學都能夠順利訓練!\n",
    "\n",
    "\n",
    "最後一天的作業請閱讀這篇非常詳盡的[文章](https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/)，基本上已經涵蓋了所有訓練　CNN 常用的技巧，請使用所有學過的訓練技巧，盡可能地提高 Cifar-10 的 test data 準確率，截圖你最佳的結果並上傳來完成最後一次的作業吧!\n",
    "\n",
    "另外這些技巧在 Kaggle 上也會被許多人使用，更有人會開發一些新的技巧，例如使把預訓練在 ImageNet 上的模型當成 feature extractor 後，再拿擷取出的特徵重新訓練新的模型，這些技巧再進階的課程我們會在提到，有興趣的同學也可以[參考](https://www.kaggle.com/insaff/img-feature-extraction-with-pretrained-resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根據 resnet_builder.py 撰寫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu==1.14\n",
      "  Using cached https://files.pythonhosted.org/packages/81/d1/9222b9aac2fa27dccaef38917cde84c24888f3cd0dd139c7e12be9f49a7a/tensorflow_gpu-1.14.0-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in d:\\anaconda\\lib\\site-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-gpu==1.14) (0.2.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in d:\\anaconda\\lib\\site-packages (from tensorflow-gpu==1.14) (1.25.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in d:\\anaconda\\lib\\site-packages (from tensorflow-gpu==1.14) (1.17.2)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in c:\\users\\moren\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow-gpu==1.14) (1.14.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in d:\\anaconda\\lib\\site-packages (from tensorflow-gpu==1.14) (1.0.8)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in d:\\anaconda\\lib\\site-packages (from tensorflow-gpu==1.14) (1.11.2)\n",
      "Requirement already satisfied: wheel>=0.26 in d:\\anaconda\\lib\\site-packages (from tensorflow-gpu==1.14) (0.32.3)\n",
      "Requirement already satisfied: six>=1.10.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-gpu==1.14) (1.12.0)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in c:\\users\\moren\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow-gpu==1.14) (1.14.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in d:\\anaconda\\lib\\site-packages (from tensorflow-gpu==1.14) (3.10.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-gpu==1.14) (0.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in d:\\anaconda\\lib\\site-packages (from tensorflow-gpu==1.14) (0.1.8)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-gpu==1.14) (0.8.1)\n",
      "Requirement already satisfied: h5py in d:\\anaconda\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14) (2.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\anaconda\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in d:\\anaconda\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (0.14.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\anaconda\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (41.6.0)\n",
      "Installing collected packages: tensorflow-gpu\n",
      "Successfully installed tensorflow-gpu-1.14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts freeze_graph.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\moren\\AppData\\Roaming\\Python\\Python37\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu==1.14 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moren\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\moren\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\moren\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\moren\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\moren\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\moren\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\moren\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\moren\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\moren\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\moren\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\moren\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\moren\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15175965472859124217\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6696213545\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2320086988227082744\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    " \n",
    "KTF.set_session(tf.Session(config=tf.ConfigProto(device_count={'gpu':0})))\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  \n",
    "epochs = 50\n",
    "data_augmentation = True\n",
    "num_classes = 10\n",
    "n = 16\n",
    "depth = 6 * n + 2\n",
    "\n",
    "subtract_pixel_mean = True\n",
    "version = 1\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "if subtract_pixel_mean:\n",
    "    x_train_mean = np.mean(x_train, axis=0)\n",
    "    x_train -= x_train_mean \n",
    "    x_test -= x_train_mean \n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lr = 1e-5\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-5\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "def resnet_v1(input_shape, depth = depth, num_classes=10):\n",
    "   \n",
    "    #if (depth - 2) % 6 != 0:\n",
    "    #    raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    \n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    \n",
    "    for stack in range(3):\n",
    "        \n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  \n",
    "                strides = 2  \n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if stack > 0 and res_block == 0: \n",
    "                \n",
    "                \n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y]) \n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    \n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  1e-05\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_370 (Conv2D)             (None, 32, 32, 16)   448         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_360 (BatchN (None, 32, 32, 16)   64          conv2d_370[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_360 (Activation)     (None, 32, 32, 16)   0           batch_normalization_360[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_371 (Conv2D)             (None, 32, 32, 16)   2320        activation_360[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_361 (BatchN (None, 32, 32, 16)   64          conv2d_371[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_361 (Activation)     (None, 32, 32, 16)   0           batch_normalization_361[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_372 (Conv2D)             (None, 32, 32, 16)   2320        activation_361[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_362 (BatchN (None, 32, 32, 16)   64          conv2d_372[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_178 (Add)                   (None, 32, 32, 16)   0           activation_360[0][0]             \n",
      "                                                                 batch_normalization_362[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_362 (Activation)     (None, 32, 32, 16)   0           add_178[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_373 (Conv2D)             (None, 32, 32, 16)   2320        activation_362[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_363 (BatchN (None, 32, 32, 16)   64          conv2d_373[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_363 (Activation)     (None, 32, 32, 16)   0           batch_normalization_363[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_374 (Conv2D)             (None, 32, 32, 16)   2320        activation_363[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_364 (BatchN (None, 32, 32, 16)   64          conv2d_374[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_179 (Add)                   (None, 32, 32, 16)   0           activation_362[0][0]             \n",
      "                                                                 batch_normalization_364[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_364 (Activation)     (None, 32, 32, 16)   0           add_179[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_375 (Conv2D)             (None, 32, 32, 16)   2320        activation_364[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_365 (BatchN (None, 32, 32, 16)   64          conv2d_375[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_365 (Activation)     (None, 32, 32, 16)   0           batch_normalization_365[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_376 (Conv2D)             (None, 32, 32, 16)   2320        activation_365[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_366 (BatchN (None, 32, 32, 16)   64          conv2d_376[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_180 (Add)                   (None, 32, 32, 16)   0           activation_364[0][0]             \n",
      "                                                                 batch_normalization_366[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_366 (Activation)     (None, 32, 32, 16)   0           add_180[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_377 (Conv2D)             (None, 32, 32, 16)   2320        activation_366[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_367 (BatchN (None, 32, 32, 16)   64          conv2d_377[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_367 (Activation)     (None, 32, 32, 16)   0           batch_normalization_367[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_378 (Conv2D)             (None, 32, 32, 16)   2320        activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_368 (BatchN (None, 32, 32, 16)   64          conv2d_378[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_181 (Add)                   (None, 32, 32, 16)   0           activation_366[0][0]             \n",
      "                                                                 batch_normalization_368[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_368 (Activation)     (None, 32, 32, 16)   0           add_181[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_379 (Conv2D)             (None, 32, 32, 16)   2320        activation_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_369 (BatchN (None, 32, 32, 16)   64          conv2d_379[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_369 (Activation)     (None, 32, 32, 16)   0           batch_normalization_369[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_380 (Conv2D)             (None, 32, 32, 16)   2320        activation_369[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_370 (BatchN (None, 32, 32, 16)   64          conv2d_380[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_182 (Add)                   (None, 32, 32, 16)   0           activation_368[0][0]             \n",
      "                                                                 batch_normalization_370[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_370 (Activation)     (None, 32, 32, 16)   0           add_182[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_381 (Conv2D)             (None, 32, 32, 16)   2320        activation_370[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_371 (BatchN (None, 32, 32, 16)   64          conv2d_381[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_371 (Activation)     (None, 32, 32, 16)   0           batch_normalization_371[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_382 (Conv2D)             (None, 32, 32, 16)   2320        activation_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_372 (BatchN (None, 32, 32, 16)   64          conv2d_382[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_183 (Add)                   (None, 32, 32, 16)   0           activation_370[0][0]             \n",
      "                                                                 batch_normalization_372[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_372 (Activation)     (None, 32, 32, 16)   0           add_183[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_383 (Conv2D)             (None, 32, 32, 16)   2320        activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_373 (BatchN (None, 32, 32, 16)   64          conv2d_383[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_373 (Activation)     (None, 32, 32, 16)   0           batch_normalization_373[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_384 (Conv2D)             (None, 32, 32, 16)   2320        activation_373[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_374 (BatchN (None, 32, 32, 16)   64          conv2d_384[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_184 (Add)                   (None, 32, 32, 16)   0           activation_372[0][0]             \n",
      "                                                                 batch_normalization_374[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_374 (Activation)     (None, 32, 32, 16)   0           add_184[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_385 (Conv2D)             (None, 32, 32, 16)   2320        activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_375 (BatchN (None, 32, 32, 16)   64          conv2d_385[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_375 (Activation)     (None, 32, 32, 16)   0           batch_normalization_375[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_386 (Conv2D)             (None, 32, 32, 16)   2320        activation_375[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_376 (BatchN (None, 32, 32, 16)   64          conv2d_386[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_185 (Add)                   (None, 32, 32, 16)   0           activation_374[0][0]             \n",
      "                                                                 batch_normalization_376[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_376 (Activation)     (None, 32, 32, 16)   0           add_185[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_387 (Conv2D)             (None, 32, 32, 16)   2320        activation_376[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_377 (BatchN (None, 32, 32, 16)   64          conv2d_387[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_377 (Activation)     (None, 32, 32, 16)   0           batch_normalization_377[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_388 (Conv2D)             (None, 32, 32, 16)   2320        activation_377[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_378 (BatchN (None, 32, 32, 16)   64          conv2d_388[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_186 (Add)                   (None, 32, 32, 16)   0           activation_376[0][0]             \n",
      "                                                                 batch_normalization_378[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_378 (Activation)     (None, 32, 32, 16)   0           add_186[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_389 (Conv2D)             (None, 32, 32, 16)   2320        activation_378[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_379 (BatchN (None, 32, 32, 16)   64          conv2d_389[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_379 (Activation)     (None, 32, 32, 16)   0           batch_normalization_379[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_390 (Conv2D)             (None, 32, 32, 16)   2320        activation_379[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_380 (BatchN (None, 32, 32, 16)   64          conv2d_390[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_187 (Add)                   (None, 32, 32, 16)   0           activation_378[0][0]             \n",
      "                                                                 batch_normalization_380[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_380 (Activation)     (None, 32, 32, 16)   0           add_187[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_391 (Conv2D)             (None, 32, 32, 16)   2320        activation_380[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_381 (BatchN (None, 32, 32, 16)   64          conv2d_391[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_381 (Activation)     (None, 32, 32, 16)   0           batch_normalization_381[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_392 (Conv2D)             (None, 32, 32, 16)   2320        activation_381[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_382 (BatchN (None, 32, 32, 16)   64          conv2d_392[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_188 (Add)                   (None, 32, 32, 16)   0           activation_380[0][0]             \n",
      "                                                                 batch_normalization_382[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_382 (Activation)     (None, 32, 32, 16)   0           add_188[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_393 (Conv2D)             (None, 32, 32, 16)   2320        activation_382[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_383 (BatchN (None, 32, 32, 16)   64          conv2d_393[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_383 (Activation)     (None, 32, 32, 16)   0           batch_normalization_383[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_394 (Conv2D)             (None, 32, 32, 16)   2320        activation_383[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_384 (BatchN (None, 32, 32, 16)   64          conv2d_394[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_189 (Add)                   (None, 32, 32, 16)   0           activation_382[0][0]             \n",
      "                                                                 batch_normalization_384[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_384 (Activation)     (None, 32, 32, 16)   0           add_189[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_395 (Conv2D)             (None, 32, 32, 16)   2320        activation_384[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_385 (BatchN (None, 32, 32, 16)   64          conv2d_395[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_385 (Activation)     (None, 32, 32, 16)   0           batch_normalization_385[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_396 (Conv2D)             (None, 32, 32, 16)   2320        activation_385[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_386 (BatchN (None, 32, 32, 16)   64          conv2d_396[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_190 (Add)                   (None, 32, 32, 16)   0           activation_384[0][0]             \n",
      "                                                                 batch_normalization_386[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_386 (Activation)     (None, 32, 32, 16)   0           add_190[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_397 (Conv2D)             (None, 32, 32, 16)   2320        activation_386[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_387 (BatchN (None, 32, 32, 16)   64          conv2d_397[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_387 (Activation)     (None, 32, 32, 16)   0           batch_normalization_387[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_398 (Conv2D)             (None, 32, 32, 16)   2320        activation_387[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_388 (BatchN (None, 32, 32, 16)   64          conv2d_398[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_191 (Add)                   (None, 32, 32, 16)   0           activation_386[0][0]             \n",
      "                                                                 batch_normalization_388[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_388 (Activation)     (None, 32, 32, 16)   0           add_191[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_399 (Conv2D)             (None, 32, 32, 16)   2320        activation_388[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_389 (BatchN (None, 32, 32, 16)   64          conv2d_399[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_389 (Activation)     (None, 32, 32, 16)   0           batch_normalization_389[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_400 (Conv2D)             (None, 32, 32, 16)   2320        activation_389[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_390 (BatchN (None, 32, 32, 16)   64          conv2d_400[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_192 (Add)                   (None, 32, 32, 16)   0           activation_388[0][0]             \n",
      "                                                                 batch_normalization_390[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_390 (Activation)     (None, 32, 32, 16)   0           add_192[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_401 (Conv2D)             (None, 32, 32, 16)   2320        activation_390[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_391 (BatchN (None, 32, 32, 16)   64          conv2d_401[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_391 (Activation)     (None, 32, 32, 16)   0           batch_normalization_391[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_402 (Conv2D)             (None, 32, 32, 16)   2320        activation_391[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_392 (BatchN (None, 32, 32, 16)   64          conv2d_402[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_193 (Add)                   (None, 32, 32, 16)   0           activation_390[0][0]             \n",
      "                                                                 batch_normalization_392[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_392 (Activation)     (None, 32, 32, 16)   0           add_193[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_403 (Conv2D)             (None, 16, 16, 32)   4640        activation_392[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_393 (BatchN (None, 16, 16, 32)   128         conv2d_403[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_393 (Activation)     (None, 16, 16, 32)   0           batch_normalization_393[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_404 (Conv2D)             (None, 16, 16, 32)   9248        activation_393[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_405 (Conv2D)             (None, 16, 16, 32)   544         activation_392[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_394 (BatchN (None, 16, 16, 32)   128         conv2d_404[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_194 (Add)                   (None, 16, 16, 32)   0           conv2d_405[0][0]                 \n",
      "                                                                 batch_normalization_394[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_394 (Activation)     (None, 16, 16, 32)   0           add_194[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_406 (Conv2D)             (None, 16, 16, 32)   9248        activation_394[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_395 (BatchN (None, 16, 16, 32)   128         conv2d_406[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_395 (Activation)     (None, 16, 16, 32)   0           batch_normalization_395[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_407 (Conv2D)             (None, 16, 16, 32)   9248        activation_395[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_396 (BatchN (None, 16, 16, 32)   128         conv2d_407[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_195 (Add)                   (None, 16, 16, 32)   0           activation_394[0][0]             \n",
      "                                                                 batch_normalization_396[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_396 (Activation)     (None, 16, 16, 32)   0           add_195[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_408 (Conv2D)             (None, 16, 16, 32)   9248        activation_396[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_397 (BatchN (None, 16, 16, 32)   128         conv2d_408[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_397 (Activation)     (None, 16, 16, 32)   0           batch_normalization_397[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_409 (Conv2D)             (None, 16, 16, 32)   9248        activation_397[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_398 (BatchN (None, 16, 16, 32)   128         conv2d_409[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_196 (Add)                   (None, 16, 16, 32)   0           activation_396[0][0]             \n",
      "                                                                 batch_normalization_398[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_398 (Activation)     (None, 16, 16, 32)   0           add_196[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_410 (Conv2D)             (None, 16, 16, 32)   9248        activation_398[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_399 (BatchN (None, 16, 16, 32)   128         conv2d_410[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_399 (Activation)     (None, 16, 16, 32)   0           batch_normalization_399[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_411 (Conv2D)             (None, 16, 16, 32)   9248        activation_399[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_400 (BatchN (None, 16, 16, 32)   128         conv2d_411[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_197 (Add)                   (None, 16, 16, 32)   0           activation_398[0][0]             \n",
      "                                                                 batch_normalization_400[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_400 (Activation)     (None, 16, 16, 32)   0           add_197[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_412 (Conv2D)             (None, 16, 16, 32)   9248        activation_400[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_401 (BatchN (None, 16, 16, 32)   128         conv2d_412[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_401 (Activation)     (None, 16, 16, 32)   0           batch_normalization_401[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_413 (Conv2D)             (None, 16, 16, 32)   9248        activation_401[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_402 (BatchN (None, 16, 16, 32)   128         conv2d_413[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_198 (Add)                   (None, 16, 16, 32)   0           activation_400[0][0]             \n",
      "                                                                 batch_normalization_402[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_402 (Activation)     (None, 16, 16, 32)   0           add_198[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_414 (Conv2D)             (None, 16, 16, 32)   9248        activation_402[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_403 (BatchN (None, 16, 16, 32)   128         conv2d_414[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_403 (Activation)     (None, 16, 16, 32)   0           batch_normalization_403[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_415 (Conv2D)             (None, 16, 16, 32)   9248        activation_403[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_404 (BatchN (None, 16, 16, 32)   128         conv2d_415[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_199 (Add)                   (None, 16, 16, 32)   0           activation_402[0][0]             \n",
      "                                                                 batch_normalization_404[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_404 (Activation)     (None, 16, 16, 32)   0           add_199[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_416 (Conv2D)             (None, 16, 16, 32)   9248        activation_404[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_405 (BatchN (None, 16, 16, 32)   128         conv2d_416[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_405 (Activation)     (None, 16, 16, 32)   0           batch_normalization_405[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_417 (Conv2D)             (None, 16, 16, 32)   9248        activation_405[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_406 (BatchN (None, 16, 16, 32)   128         conv2d_417[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_200 (Add)                   (None, 16, 16, 32)   0           activation_404[0][0]             \n",
      "                                                                 batch_normalization_406[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_406 (Activation)     (None, 16, 16, 32)   0           add_200[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_418 (Conv2D)             (None, 16, 16, 32)   9248        activation_406[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_407 (BatchN (None, 16, 16, 32)   128         conv2d_418[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_407 (Activation)     (None, 16, 16, 32)   0           batch_normalization_407[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_419 (Conv2D)             (None, 16, 16, 32)   9248        activation_407[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_408 (BatchN (None, 16, 16, 32)   128         conv2d_419[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_201 (Add)                   (None, 16, 16, 32)   0           activation_406[0][0]             \n",
      "                                                                 batch_normalization_408[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_408 (Activation)     (None, 16, 16, 32)   0           add_201[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_420 (Conv2D)             (None, 16, 16, 32)   9248        activation_408[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_409 (BatchN (None, 16, 16, 32)   128         conv2d_420[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_409 (Activation)     (None, 16, 16, 32)   0           batch_normalization_409[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_421 (Conv2D)             (None, 16, 16, 32)   9248        activation_409[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_410 (BatchN (None, 16, 16, 32)   128         conv2d_421[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_202 (Add)                   (None, 16, 16, 32)   0           activation_408[0][0]             \n",
      "                                                                 batch_normalization_410[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_410 (Activation)     (None, 16, 16, 32)   0           add_202[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_422 (Conv2D)             (None, 16, 16, 32)   9248        activation_410[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_411 (BatchN (None, 16, 16, 32)   128         conv2d_422[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_411 (Activation)     (None, 16, 16, 32)   0           batch_normalization_411[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_423 (Conv2D)             (None, 16, 16, 32)   9248        activation_411[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_412 (BatchN (None, 16, 16, 32)   128         conv2d_423[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_203 (Add)                   (None, 16, 16, 32)   0           activation_410[0][0]             \n",
      "                                                                 batch_normalization_412[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_412 (Activation)     (None, 16, 16, 32)   0           add_203[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_424 (Conv2D)             (None, 16, 16, 32)   9248        activation_412[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_413 (BatchN (None, 16, 16, 32)   128         conv2d_424[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_413 (Activation)     (None, 16, 16, 32)   0           batch_normalization_413[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_425 (Conv2D)             (None, 16, 16, 32)   9248        activation_413[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_414 (BatchN (None, 16, 16, 32)   128         conv2d_425[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_204 (Add)                   (None, 16, 16, 32)   0           activation_412[0][0]             \n",
      "                                                                 batch_normalization_414[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_414 (Activation)     (None, 16, 16, 32)   0           add_204[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_426 (Conv2D)             (None, 16, 16, 32)   9248        activation_414[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_415 (BatchN (None, 16, 16, 32)   128         conv2d_426[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_415 (Activation)     (None, 16, 16, 32)   0           batch_normalization_415[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_427 (Conv2D)             (None, 16, 16, 32)   9248        activation_415[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_416 (BatchN (None, 16, 16, 32)   128         conv2d_427[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_205 (Add)                   (None, 16, 16, 32)   0           activation_414[0][0]             \n",
      "                                                                 batch_normalization_416[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_416 (Activation)     (None, 16, 16, 32)   0           add_205[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_428 (Conv2D)             (None, 16, 16, 32)   9248        activation_416[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_417 (BatchN (None, 16, 16, 32)   128         conv2d_428[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_417 (Activation)     (None, 16, 16, 32)   0           batch_normalization_417[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_429 (Conv2D)             (None, 16, 16, 32)   9248        activation_417[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_418 (BatchN (None, 16, 16, 32)   128         conv2d_429[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_206 (Add)                   (None, 16, 16, 32)   0           activation_416[0][0]             \n",
      "                                                                 batch_normalization_418[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_418 (Activation)     (None, 16, 16, 32)   0           add_206[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_430 (Conv2D)             (None, 16, 16, 32)   9248        activation_418[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_419 (BatchN (None, 16, 16, 32)   128         conv2d_430[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_419 (Activation)     (None, 16, 16, 32)   0           batch_normalization_419[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_431 (Conv2D)             (None, 16, 16, 32)   9248        activation_419[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_420 (BatchN (None, 16, 16, 32)   128         conv2d_431[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_207 (Add)                   (None, 16, 16, 32)   0           activation_418[0][0]             \n",
      "                                                                 batch_normalization_420[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_420 (Activation)     (None, 16, 16, 32)   0           add_207[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_432 (Conv2D)             (None, 16, 16, 32)   9248        activation_420[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_421 (BatchN (None, 16, 16, 32)   128         conv2d_432[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_421 (Activation)     (None, 16, 16, 32)   0           batch_normalization_421[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_433 (Conv2D)             (None, 16, 16, 32)   9248        activation_421[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_422 (BatchN (None, 16, 16, 32)   128         conv2d_433[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_208 (Add)                   (None, 16, 16, 32)   0           activation_420[0][0]             \n",
      "                                                                 batch_normalization_422[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_422 (Activation)     (None, 16, 16, 32)   0           add_208[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_434 (Conv2D)             (None, 16, 16, 32)   9248        activation_422[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_423 (BatchN (None, 16, 16, 32)   128         conv2d_434[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_423 (Activation)     (None, 16, 16, 32)   0           batch_normalization_423[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_435 (Conv2D)             (None, 16, 16, 32)   9248        activation_423[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_424 (BatchN (None, 16, 16, 32)   128         conv2d_435[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_209 (Add)                   (None, 16, 16, 32)   0           activation_422[0][0]             \n",
      "                                                                 batch_normalization_424[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_424 (Activation)     (None, 16, 16, 32)   0           add_209[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_436 (Conv2D)             (None, 8, 8, 64)     18496       activation_424[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_425 (BatchN (None, 8, 8, 64)     256         conv2d_436[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_425 (Activation)     (None, 8, 8, 64)     0           batch_normalization_425[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_437 (Conv2D)             (None, 8, 8, 64)     36928       activation_425[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_438 (Conv2D)             (None, 8, 8, 64)     2112        activation_424[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_426 (BatchN (None, 8, 8, 64)     256         conv2d_437[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_210 (Add)                   (None, 8, 8, 64)     0           conv2d_438[0][0]                 \n",
      "                                                                 batch_normalization_426[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_426 (Activation)     (None, 8, 8, 64)     0           add_210[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_439 (Conv2D)             (None, 8, 8, 64)     36928       activation_426[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_427 (BatchN (None, 8, 8, 64)     256         conv2d_439[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_427 (Activation)     (None, 8, 8, 64)     0           batch_normalization_427[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_440 (Conv2D)             (None, 8, 8, 64)     36928       activation_427[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_428 (BatchN (None, 8, 8, 64)     256         conv2d_440[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_211 (Add)                   (None, 8, 8, 64)     0           activation_426[0][0]             \n",
      "                                                                 batch_normalization_428[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_428 (Activation)     (None, 8, 8, 64)     0           add_211[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_441 (Conv2D)             (None, 8, 8, 64)     36928       activation_428[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_429 (BatchN (None, 8, 8, 64)     256         conv2d_441[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_429 (Activation)     (None, 8, 8, 64)     0           batch_normalization_429[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_442 (Conv2D)             (None, 8, 8, 64)     36928       activation_429[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_430 (BatchN (None, 8, 8, 64)     256         conv2d_442[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_212 (Add)                   (None, 8, 8, 64)     0           activation_428[0][0]             \n",
      "                                                                 batch_normalization_430[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_430 (Activation)     (None, 8, 8, 64)     0           add_212[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_443 (Conv2D)             (None, 8, 8, 64)     36928       activation_430[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_431 (BatchN (None, 8, 8, 64)     256         conv2d_443[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_431 (Activation)     (None, 8, 8, 64)     0           batch_normalization_431[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_444 (Conv2D)             (None, 8, 8, 64)     36928       activation_431[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_432 (BatchN (None, 8, 8, 64)     256         conv2d_444[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_213 (Add)                   (None, 8, 8, 64)     0           activation_430[0][0]             \n",
      "                                                                 batch_normalization_432[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_432 (Activation)     (None, 8, 8, 64)     0           add_213[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_445 (Conv2D)             (None, 8, 8, 64)     36928       activation_432[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_433 (BatchN (None, 8, 8, 64)     256         conv2d_445[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_433 (Activation)     (None, 8, 8, 64)     0           batch_normalization_433[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_446 (Conv2D)             (None, 8, 8, 64)     36928       activation_433[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_434 (BatchN (None, 8, 8, 64)     256         conv2d_446[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_214 (Add)                   (None, 8, 8, 64)     0           activation_432[0][0]             \n",
      "                                                                 batch_normalization_434[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_434 (Activation)     (None, 8, 8, 64)     0           add_214[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_447 (Conv2D)             (None, 8, 8, 64)     36928       activation_434[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_435 (BatchN (None, 8, 8, 64)     256         conv2d_447[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_435 (Activation)     (None, 8, 8, 64)     0           batch_normalization_435[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_448 (Conv2D)             (None, 8, 8, 64)     36928       activation_435[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_436 (BatchN (None, 8, 8, 64)     256         conv2d_448[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_215 (Add)                   (None, 8, 8, 64)     0           activation_434[0][0]             \n",
      "                                                                 batch_normalization_436[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_436 (Activation)     (None, 8, 8, 64)     0           add_215[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_449 (Conv2D)             (None, 8, 8, 64)     36928       activation_436[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_437 (BatchN (None, 8, 8, 64)     256         conv2d_449[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_437 (Activation)     (None, 8, 8, 64)     0           batch_normalization_437[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_450 (Conv2D)             (None, 8, 8, 64)     36928       activation_437[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_438 (BatchN (None, 8, 8, 64)     256         conv2d_450[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_216 (Add)                   (None, 8, 8, 64)     0           activation_436[0][0]             \n",
      "                                                                 batch_normalization_438[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_438 (Activation)     (None, 8, 8, 64)     0           add_216[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_451 (Conv2D)             (None, 8, 8, 64)     36928       activation_438[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_439 (BatchN (None, 8, 8, 64)     256         conv2d_451[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_439 (Activation)     (None, 8, 8, 64)     0           batch_normalization_439[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_452 (Conv2D)             (None, 8, 8, 64)     36928       activation_439[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_440 (BatchN (None, 8, 8, 64)     256         conv2d_452[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_217 (Add)                   (None, 8, 8, 64)     0           activation_438[0][0]             \n",
      "                                                                 batch_normalization_440[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_440 (Activation)     (None, 8, 8, 64)     0           add_217[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_453 (Conv2D)             (None, 8, 8, 64)     36928       activation_440[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_441 (BatchN (None, 8, 8, 64)     256         conv2d_453[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_441 (Activation)     (None, 8, 8, 64)     0           batch_normalization_441[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_454 (Conv2D)             (None, 8, 8, 64)     36928       activation_441[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_442 (BatchN (None, 8, 8, 64)     256         conv2d_454[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_218 (Add)                   (None, 8, 8, 64)     0           activation_440[0][0]             \n",
      "                                                                 batch_normalization_442[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_442 (Activation)     (None, 8, 8, 64)     0           add_218[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_455 (Conv2D)             (None, 8, 8, 64)     36928       activation_442[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_443 (BatchN (None, 8, 8, 64)     256         conv2d_455[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_443 (Activation)     (None, 8, 8, 64)     0           batch_normalization_443[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_456 (Conv2D)             (None, 8, 8, 64)     36928       activation_443[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_444 (BatchN (None, 8, 8, 64)     256         conv2d_456[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_219 (Add)                   (None, 8, 8, 64)     0           activation_442[0][0]             \n",
      "                                                                 batch_normalization_444[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_444 (Activation)     (None, 8, 8, 64)     0           add_219[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_457 (Conv2D)             (None, 8, 8, 64)     36928       activation_444[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_445 (BatchN (None, 8, 8, 64)     256         conv2d_457[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_445 (Activation)     (None, 8, 8, 64)     0           batch_normalization_445[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_458 (Conv2D)             (None, 8, 8, 64)     36928       activation_445[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_446 (BatchN (None, 8, 8, 64)     256         conv2d_458[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_220 (Add)                   (None, 8, 8, 64)     0           activation_444[0][0]             \n",
      "                                                                 batch_normalization_446[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_446 (Activation)     (None, 8, 8, 64)     0           add_220[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_459 (Conv2D)             (None, 8, 8, 64)     36928       activation_446[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_447 (BatchN (None, 8, 8, 64)     256         conv2d_459[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_447 (Activation)     (None, 8, 8, 64)     0           batch_normalization_447[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_460 (Conv2D)             (None, 8, 8, 64)     36928       activation_447[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_448 (BatchN (None, 8, 8, 64)     256         conv2d_460[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_221 (Add)                   (None, 8, 8, 64)     0           activation_446[0][0]             \n",
      "                                                                 batch_normalization_448[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_448 (Activation)     (None, 8, 8, 64)     0           add_221[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_461 (Conv2D)             (None, 8, 8, 64)     36928       activation_448[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_449 (BatchN (None, 8, 8, 64)     256         conv2d_461[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_449 (Activation)     (None, 8, 8, 64)     0           batch_normalization_449[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_462 (Conv2D)             (None, 8, 8, 64)     36928       activation_449[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_450 (BatchN (None, 8, 8, 64)     256         conv2d_462[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_222 (Add)                   (None, 8, 8, 64)     0           activation_448[0][0]             \n",
      "                                                                 batch_normalization_450[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_450 (Activation)     (None, 8, 8, 64)     0           add_222[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_463 (Conv2D)             (None, 8, 8, 64)     36928       activation_450[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_451 (BatchN (None, 8, 8, 64)     256         conv2d_463[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_451 (Activation)     (None, 8, 8, 64)     0           batch_normalization_451[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_464 (Conv2D)             (None, 8, 8, 64)     36928       activation_451[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_452 (BatchN (None, 8, 8, 64)     256         conv2d_464[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_223 (Add)                   (None, 8, 8, 64)     0           activation_450[0][0]             \n",
      "                                                                 batch_normalization_452[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_452 (Activation)     (None, 8, 8, 64)     0           add_223[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_465 (Conv2D)             (None, 8, 8, 64)     36928       activation_452[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_453 (BatchN (None, 8, 8, 64)     256         conv2d_465[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_453 (Activation)     (None, 8, 8, 64)     0           batch_normalization_453[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_466 (Conv2D)             (None, 8, 8, 64)     36928       activation_453[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_454 (BatchN (None, 8, 8, 64)     256         conv2d_466[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_224 (Add)                   (None, 8, 8, 64)     0           activation_452[0][0]             \n",
      "                                                                 batch_normalization_454[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_454 (Activation)     (None, 8, 8, 64)     0           add_224[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_467 (Conv2D)             (None, 8, 8, 64)     36928       activation_454[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_455 (BatchN (None, 8, 8, 64)     256         conv2d_467[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_455 (Activation)     (None, 8, 8, 64)     0           batch_normalization_455[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_468 (Conv2D)             (None, 8, 8, 64)     36928       activation_455[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_456 (BatchN (None, 8, 8, 64)     256         conv2d_468[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_225 (Add)                   (None, 8, 8, 64)     0           activation_454[0][0]             \n",
      "                                                                 batch_normalization_456[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_456 (Activation)     (None, 8, 8, 64)     0           add_225[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 1, 1, 64)     0           activation_456[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 64)           0           average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           650         flatten_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,546,986\n",
      "Trainable params: 1,539,786\n",
      "Non-trainable params: 7,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = resnet_v1(input_shape=input_shape, depth= depth)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [lr_reducer, lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一種設定\n",
    "datagen = ImageDataGenerator(    \n",
    "    featurewise_center=False,    \n",
    "    samplewise_center=False,    \n",
    "    featurewise_std_normalization=False,    \n",
    "    samplewise_std_normalization=False,    \n",
    "    zca_whitening=False,    \n",
    "    zca_epsilon=1e-06,    \n",
    "    rotation_range=0,    \n",
    "    width_shift_range=0.1,    \n",
    "    height_shift_range=0.1,    \n",
    "    shear_range=0.,    \n",
    "    zoom_range=0.,    \n",
    "    channel_shift_range=0.,    \n",
    "    fill_mode='nearest',    \n",
    "    cval=0.,    \n",
    "    horizontal_flip=True,    \n",
    "    vertical_flip=False,    \n",
    "    rescale=None,    \n",
    "    preprocessing_function=None,    \n",
    "    data_format=None,    \n",
    "    validation_split=0.0)\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二種設定\n",
    "augment_generator = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 123s 157ms/step - loss: 1.2243 - accuracy: 0.8905 - val_loss: 1.1136 - val_accuracy: 0.8970\n",
      "Epoch 2/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 102s 130ms/step - loss: 1.0674 - accuracy: 0.8982 - val_loss: 1.0375 - val_accuracy: 0.8987\n",
      "Epoch 3/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 106s 136ms/step - loss: 1.0215 - accuracy: 0.8998 - val_loss: 1.0074 - val_accuracy: 0.8997\n",
      "Epoch 4/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 109s 140ms/step - loss: 0.9917 - accuracy: 0.9017 - val_loss: 0.9895 - val_accuracy: 0.9001\n",
      "Epoch 5/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 109s 140ms/step - loss: 0.9665 - accuracy: 0.9039 - val_loss: 0.9603 - val_accuracy: 0.9049\n",
      "Epoch 6/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 110s 140ms/step - loss: 0.9520 - accuracy: 0.9052 - val_loss: 0.9455 - val_accuracy: 0.9060\n",
      "Epoch 7/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 112s 144ms/step - loss: 0.9400 - accuracy: 0.9069 - val_loss: 0.9327 - val_accuracy: 0.9080\n",
      "Epoch 8/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 113s 145ms/step - loss: 0.9299 - accuracy: 0.9078 - val_loss: 0.9257 - val_accuracy: 0.9078\n",
      "Epoch 9/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 115s 147ms/step - loss: 0.9195 - accuracy: 0.9086 - val_loss: 0.9205 - val_accuracy: 0.9079\n",
      "Epoch 10/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 111s 143ms/step - loss: 0.9101 - accuracy: 0.9100 - val_loss: 0.9070 - val_accuracy: 0.9111\n",
      "Epoch 11/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 114s 146ms/step - loss: 0.9014 - accuracy: 0.9109 - val_loss: 0.9001 - val_accuracy: 0.9108\n",
      "Epoch 12/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 117s 150ms/step - loss: 0.8923 - accuracy: 0.9121 - val_loss: 0.8889 - val_accuracy: 0.9125\n",
      "Epoch 13/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 116s 148ms/step - loss: 0.8847 - accuracy: 0.9129 - val_loss: 0.8833 - val_accuracy: 0.9136\n",
      "Epoch 14/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.8766 - accuracy: 0.9140 - val_loss: 0.8716 - val_accuracy: 0.9149\n",
      "Epoch 15/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 116s 148ms/step - loss: 0.8693 - accuracy: 0.9148 - val_loss: 0.8655 - val_accuracy: 0.9156\n",
      "Epoch 16/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 113s 145ms/step - loss: 0.8619 - accuracy: 0.9156 - val_loss: 0.8578 - val_accuracy: 0.9165\n",
      "Epoch 17/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.8544 - accuracy: 0.9169 - val_loss: 0.8507 - val_accuracy: 0.9176\n",
      "Epoch 18/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 112s 144ms/step - loss: 0.8478 - accuracy: 0.9177 - val_loss: 0.8421 - val_accuracy: 0.9184\n",
      "Epoch 19/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 114s 146ms/step - loss: 0.8412 - accuracy: 0.9181 - val_loss: 0.8383 - val_accuracy: 0.9188\n",
      "Epoch 20/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 115s 147ms/step - loss: 0.8343 - accuracy: 0.9192 - val_loss: 0.8298 - val_accuracy: 0.9199\n",
      "Epoch 21/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 113s 145ms/step - loss: 0.8286 - accuracy: 0.9197 - val_loss: 0.8257 - val_accuracy: 0.9201\n",
      "Epoch 22/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 116s 149ms/step - loss: 0.8227 - accuracy: 0.9203 - val_loss: 0.8226 - val_accuracy: 0.9197\n",
      "Epoch 23/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 115s 147ms/step - loss: 0.8162 - accuracy: 0.9218 - val_loss: 0.8127 - val_accuracy: 0.9215\n",
      "Epoch 24/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 113s 145ms/step - loss: 0.8107 - accuracy: 0.9220 - val_loss: 0.8072 - val_accuracy: 0.9228\n",
      "Epoch 25/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 114s 146ms/step - loss: 0.8046 - accuracy: 0.9230 - val_loss: 0.8037 - val_accuracy: 0.9225\n",
      "Epoch 26/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 116s 148ms/step - loss: 0.7992 - accuracy: 0.9236 - val_loss: 0.7988 - val_accuracy: 0.9229\n",
      "Epoch 27/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 116s 148ms/step - loss: 0.7938 - accuracy: 0.9242 - val_loss: 0.7886 - val_accuracy: 0.9254\n",
      "Epoch 28/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 112s 144ms/step - loss: 0.7884 - accuracy: 0.9250 - val_loss: 0.7846 - val_accuracy: 0.9253\n",
      "Epoch 29/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 110s 141ms/step - loss: 0.7828 - accuracy: 0.9255 - val_loss: 0.7879 - val_accuracy: 0.9233\n",
      "Epoch 30/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 110s 141ms/step - loss: 0.7782 - accuracy: 0.9262 - val_loss: 0.7782 - val_accuracy: 0.9254\n",
      "Epoch 31/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 110s 141ms/step - loss: 0.7723 - accuracy: 0.9272 - val_loss: 0.7744 - val_accuracy: 0.9249\n",
      "Epoch 32/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 110s 141ms/step - loss: 0.7678 - accuracy: 0.9276 - val_loss: 0.7730 - val_accuracy: 0.9249\n",
      "Epoch 33/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 110s 141ms/step - loss: 0.7627 - accuracy: 0.9279 - val_loss: 0.7606 - val_accuracy: 0.9279\n",
      "Epoch 34/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 114s 146ms/step - loss: 0.7581 - accuracy: 0.9285 - val_loss: 0.7693 - val_accuracy: 0.9244\n",
      "Epoch 35/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.7535 - accuracy: 0.9291 - val_loss: 0.7575 - val_accuracy: 0.9277\n",
      "Epoch 36/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 110s 141ms/step - loss: 0.7491 - accuracy: 0.9298 - val_loss: 0.7522 - val_accuracy: 0.9277\n",
      "Epoch 37/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 109s 140ms/step - loss: 0.7446 - accuracy: 0.9305 - val_loss: 0.7542 - val_accuracy: 0.9266\n",
      "Epoch 38/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 111s 142ms/step - loss: 0.7405 - accuracy: 0.9308 - val_loss: 0.7424 - val_accuracy: 0.9289\n",
      "Epoch 39/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 110s 141ms/step - loss: 0.7365 - accuracy: 0.9310 - val_loss: 0.7419 - val_accuracy: 0.9288\n",
      "Epoch 40/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 111s 142ms/step - loss: 0.7316 - accuracy: 0.9319 - val_loss: 0.7394 - val_accuracy: 0.9284\n",
      "Epoch 41/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 109s 139ms/step - loss: 0.7274 - accuracy: 0.9321 - val_loss: 0.7288 - val_accuracy: 0.9304\n",
      "Epoch 42/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 109s 139ms/step - loss: 0.7228 - accuracy: 0.9332 - val_loss: 0.7241 - val_accuracy: 0.9313\n",
      "Epoch 43/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.7192 - accuracy: 0.9334 - val_loss: 0.7225 - val_accuracy: 0.9313\n",
      "Epoch 44/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 110s 141ms/step - loss: 0.7147 - accuracy: 0.9341 - val_loss: 0.7173 - val_accuracy: 0.9319\n",
      "Epoch 45/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 111s 142ms/step - loss: 0.7111 - accuracy: 0.9343 - val_loss: 0.7133 - val_accuracy: 0.9325\n",
      "Epoch 46/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 112s 143ms/step - loss: 0.7075 - accuracy: 0.9347 - val_loss: 0.7062 - val_accuracy: 0.9345\n",
      "Epoch 47/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 111s 142ms/step - loss: 0.7034 - accuracy: 0.9353 - val_loss: 0.7137 - val_accuracy: 0.9314\n",
      "Epoch 48/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 110s 141ms/step - loss: 0.7003 - accuracy: 0.9354 - val_loss: 0.7075 - val_accuracy: 0.9314\n",
      "Epoch 49/50\n",
      "Learning rate:  1e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 109s 140ms/step - loss: 0.6955 - accuracy: 0.9362 - val_loss: 0.7000 - val_accuracy: 0.9333\n",
      "Epoch 50/50\n",
      "Learning rate:  1e-05\n",
      "781/781 [==============================] - 109s 140ms/step - loss: 0.6919 - accuracy: 0.9368 - val_loss: 0.6942 - val_accuracy: 0.9352\n",
      "Test loss: 0.6941578744888306\n",
      "Test accuracy: 0.9352103471755981\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(augment_generator.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=int(len(x_train)/batch_size),\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    workers=4,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "train_acc = model.history.history[\"accuracy\"]\n",
    "valid_acc = model.history.history[\"val_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deVxV1frH8c/DDIIo4ICigrOiIIrmkGZOmWk5ppaWTTaPt8HK0lu/bpON2nCtHDLLHNI0tW6WQ+WsKc5TTogKgggoM+v3xz4aKsZRwAOH5/168fKcffbZ59mKXxZrr72WGGNQSinlvFwcXYBSSqmSpUGvlFJOToNeKaWcnAa9Uko5OQ16pZRychr0Sinl5DTolVLKyWnQK6chIstE5KSIeDq6FqVKEw165RREJBToCBjg5qv4uW5X67OUulIa9MpZ3AGsBqYAd57dKCLeIvKOiBwUkVMi8ruIeNteu1ZEVopIsogcFpERtu3LROTefMcYISK/53tuRORhEdkD7LFt+8B2jBQR2SAiHfPt7yoiL4jIPhFJtb1eS0Q+EpF38p+EiCwQkSdK4i9IlV8a9MpZ3AFMt33dICLVbNvHAa2A9kAA8CyQJyK1gcXAeKAK0ALYdBmf1xe4Bmhqe77OdowA4Gtgloh42V57ChgK9AIqAncDZ4CpwFARcQEQkSCgK/DN5Zy4UoXRoFdlnohcC9QBZhpjNgD7gNtsAXo38Lgx5ogxJtcYs9IYkwncDiwxxnxjjMk2xiQaYy4n6F83xiQZY9IBjDFf2Y6RY4x5B/AEGtn2vRcYbYzZZSybbfuuBU5hhTvAEGCZMeZ4Ef9KlDqPBr1yBncC/zPGnLA9/9q2LQjwwgr+C9W6xHZ7Hc7/RET+JSI7bN1DyYC/7fML+6ypwDDb42HAtCLUpFSB9EKSKtNs/e23Aq4icsy22ROoBAQDGUA9YPMFbz0MtLnEYU8DPvmeVy9gn3PTvtr645/DaplvM8bkichJQPJ9Vj1gawHH+QrYKiKRQBNg3iVqUuqKaYtelXV9gVysvvIWtq8mwG9Y/faTgHdFpIbtomg72/DL6UA3EblVRNxEJFBEWtiOuQnoLyI+IlIfuKeQGvyAHCABcBORl7H64s/6HHhVRBqIJUJEAgGMMbFY/fvTgDlnu4KUKk4a9KqsuxOYbIw5ZIw5dvYLmIDVDz8K2IIVpknAm4CLMeYQ1sXRf9m2bwIibcd8D8gCjmN1rUwvpIafsC7s7gYOYv0Wkb9r511gJvA/IAX4AvDO9/pUoDnabaNKiOjCI0o5loh0wurCCTXG5Dm6HuV8tEWvlAOJiDvwOPC5hrwqKRr0SjmIiDQBkrEuGr/v4HKUE9OuG6WUcnLaoldKKSdX6sbRBwUFmdDQUEeXoZRSZcqGDRtOGGOqFPRaqQv60NBQ1q9f7+gylFKqTBGRg5d6TbtulFLKyWnQK6WUk9OgV0opJ1fq+ugLkp2dTWxsLBkZGY4uRdnBy8uLkJAQ3N3dHV2KUooyEvSxsbH4+fkRGhqKiBT+BuUwxhgSExOJjY0lLCzM0eUopSgjXTcZGRkEBgZqyJcBIkJgYKD+9qVUKVImgh7QkC9D9N9KqdKlzAS9Uko5q+zcPL7fdISv1xwqkeNr0NshOTmZjz/++Ire26tXL5KTk4u5IqWUM0g+k8Uny/bR6a2lPD5jE7M2HKYk5h8rExdjHe1s0D/00EMXvZabm4urq+sl37to0aKSLO2KGWMwxuDioj/rlbra9iWkMfmP/czZcIT07Fw61A/ktX7N6Nywaol0fer/cjuMGjWKffv20aJFC5555hmWLVvG9ddfz2233Ubz5s0B6Nu3L61atSI8PJyJEyeee29oaCgnTpzgwIEDNGnShPvuu4/w8HB69OhBevrFq8YtWLCAa665hqioKLp168bx48cBSEtL46677qJ58+ZEREQwZ84cAH788UdatmxJZGQkXbt2BWDs2LGMGzfu3DGbNWvGgQMHztXw0EMP0bJlSw4fPsyDDz5IdHQ04eHhjBkz5tx71q1bR/v27YmMjKRNmzakpqbSsWNHNm3adG6fDh06EBMTU4x/00o5t93HU7l36nq6vrOcmetj6RMZzOLHOzL93rZ0aVwNF5eSub5V5lr0/16wje1xKcV6zKY1KjKmT/glX3/jjTfYunXruZBbtmwZa9euZevWreeGEE6aNImAgADS09Np3bo1AwYMIDAw8Lzj7Nmzh2+++YbPPvuMW2+9lTlz5jBs2LDz9rn22mtZvXo1IsLnn3/OW2+9xTvvvMOrr76Kv78/W7ZsAeDkyZMkJCRw3333sWLFCsLCwkhKSir0XHft2sXkyZPPdUW99tprBAQEkJubS9euXYmJiaFx48YMHjyYb7/9ltatW5OSkoK3tzf33nsvU6ZM4f3332f37t1kZmYSERFh/1+0UuVUfEoG7/68m5nrD1PB040nujVgWNs6BPl6XpXPL3NBX1q0adPmvHHiH374IXPnzgXg8OHD7Nmz56KgDwsLo0ULa/3pVq1aceDAgYuOGxsby+DBgzl69ChZWVnnPmPJkiXMmDHj3H6VK1dmwYIFdOrU6dw+AQEBhdZdp04d2rZte+75zJkzmThxIjk5ORw9epTt27cjIgQHB9O6dWsAKla01rkeNGgQr776Km+//TaTJk1ixIgRhX6eUuXZ6cwcJq74i4kr/iInL48R7cN4tEt9KlfwuKp1lLmg/6eW99VUoUKFc4+XLVvGkiVLWLVqFT4+PnTu3LnAceSenn//9HZ1dS2w6+bRRx/lqaee4uabb2bZsmWMHTsWsPrUL+y7K2gbgJubG3l5f69Kl7+W/HXv37+fcePGsW7dOipXrsyIESPIyMi45HF9fHzo3r0733//PTNnztRZRpXKJy/PcPJMFomnsziRmsnOY6l8snwfCamZ3BQRzLM3NKJOYIXCD1QCylzQO4Kfnx+pqamXfP3UqVNUrlwZHx8fdu7cyerVq6/4s06dOkXNmjUBmDp16rntPXr0YMKECbz/vrXi3MmTJ2nXrh0PP/ww+/fvP9d1ExAQQGhoKD/88AMAGzduZP/+/QV+VkpKChUqVMDf35/jx4+zePFiOnfuTOPGjYmLi2PdunW0bt2a1NRUvL29cXNz495776VPnz507NjRrt8glHJW+xLSmLMhluW7E4hPzSTpdBa5eeePmImuU5n/Dm9Fy9qVCz9gzEzIzYao24u9Vg16OwQGBtKhQweaNWvGjTfeyE033XTe6z179uTTTz8lIiKCRo0andc1crnGjh3LoEGDqFmzJm3btj0X0qNHj+bhhx+mWbNmuLq6MmbMGPr378/EiRPp378/eXl5VK1alZ9//pkBAwbw5Zdf0qJFC1q3bk3Dhg0L/KzIyEiioqIIDw+nbt26dOjQAQAPDw++/fZbHn30UdLT0/H29mbJkiX4+vrSqlUrKlasyF133XXF56hUWZV8JosFm+OYvfEImw8n4yLQtm4gzWv6E+TrSZCvB4G+ngT5elK1oid1gyrYN4rm2FaY/xiEREPkUCjm0XClbs3Y6Ohoc2GXwI4dO2jSpImDKlL5xcXF0blzZ3bu3PmPQzP130w5i5Ons/ht7wkWxRzl153xZOXm0bi6HwNahnBLVA2q+nkV7QMyTsHEzpB1Bh74DXyrXtFhRGSDMSa6oNe0Ra/s9uWXX/Liiy/y7rvv6vh75bRycvPYHJvM8t0nWL47gZjYZGpzjCjveIa3u4X+LWsSXsO/eD7MGJj3EJw8CCMWXnHIF0aDXtntjjvu4I477nB0GUoVm9w8w8HE0+w8lsqOoynsOJrC2v1JpGTk4CLQolYlnr0umHu2Pot72hGk7SAIKqaQB1g5Hnb+ADf8B+q0K77jXkCDXilVrhxKPMOUlQfYeOgku46lkp6dC4Cri1A3qAI3hFenc6OqdKgfSCVvd5g1Ak4fBVcP+OM9uOWj4inkwB+wZCw0vQXaXnzXfXHSoFdKlQu7jqXyybK9LIg5iqsIrepUZkibWjQJrkjT4IrUr+qLl/sF05lsmArb50HXMZB6FNZPgs7Pg39I0YpJPQ6z74KAMLh5ApTwjK8a9Eopp7bx0Ek+XrqPJTuO4+Phyj3XhnHPtWFUq1jIRdT4nbD4OQi7Djo8ASmxVtCvnAA3vnHlBeXmWCGfmQrD54FXxSs/lp006JVSTiErJ4/Yk2c4lGT7SjzD5thk1h04ib+3O090a8Cd7ULtuys1OwNm3w0eFaD/RGu4Y6Xa0PxW2DAFOj0NFYKurNBfX4GDf0C/iVCt6ZUd4zJp0JcQX19f0tLSiIuL47HHHmP27NkX7dO5c2fGjRtHdHSBI6KUUoUwxvDN2sN8vGwvR5LTyT9a3NPNhdDACoy+qQlD29SmgudlxN3/RkP8NrhtFvhV/3v7tU/A5m9gzafQZfTlF7xzIfzxAUTfDZGDL//9V0iDvoTVqFGjwJAvDXJycnBz028BVTadycph9NytfPfnEdqEBjCgZQi1A3yoHehDnQAfqvh5XtmUvzsXwrrPoO3D0LDH+a9VaQRNesOaidD+scvrdkn6C+Y+CDWioGcRun6ugA6GtsNzzz133sIjY8eO5Z133iEtLY2uXbvSsmVLmjdvzvfff3/Rew8cOECzZs0ASE9PZ8iQIURERDB48OAC57oBeOWVV2jdujXNmjVj5MiR5xYi2Lt3L926dSMyMpKWLVuyb98+AN566y2aN29OZGQko0aNAqzfFs7eeHbixAlCQ0MBmDJlCoMGDaJPnz706NHjH8/hyy+/JCIigsjISIYPH05qaiphYWFkZ2cD1hQKoaGh554rdbX8lZBGv49WMnfTEZ7q3pAZI9vyZPeGDGgVQuvQAKpW9LqykD91BL5/GIIjoduYgve59inIPGX119srOx1m3mFddB00FdyuzqyVZ5W95tziUXBsS/Ees3rzf7y4MmTIEJ544olzC4/MnDmTH3/8ES8vL+bOnUvFihU5ceIEbdu25eabb77kN9gnn3yCj48PMTExxMTE0LJlywL3e+SRR3j55ZcBGD58OD/88AN9+vTh9ttvZ9SoUfTr14+MjAzy8vJYvHgx8+bNY82aNfj4+Ng1VfGqVauIiYkhICCAnJycAs9h+/btvPbaa/zxxx8EBQWRlJSEn58fnTt3ZuHChfTt25cZM2YwYMAA3N3dC/1MpYrLoi1HeXZ2DO6uwtS72tCpYZWiHzTrtNUls3I85GTBgEmXDuOaLaHu9bDqI7jmfnD3Lvz4i5+zcuu2mVC5TtHrvUzaordDVFQU8fHxxMXFsXnzZipXrkzt2rUxxvDCCy8QERFBt27dOHLkyLmFQgqyYsWKc/PPR0REXHIu96VLl3LNNdfQvHlzfv31V7Zt20ZqaipHjhyhX79+AHh5eeHj48OSJUu466678PHxAeybqrh79+7n9rvUOfz6668MHDiQoKCg84577733MnnyZAAmT56sc96oqyYjO5dXf9jOQ9M3Ur+qLwsf61j0kD8VCz+PgXebwsJ/gXdlGPo1BNX/5/d1fApOx8OfXxX+GZu+ho1ToeO/oOENRav3CpW9Fn1RhjUVwcCBA5k9ezbHjh1jyJAhAEyfPp2EhAQ2bNiAu7s7oaGhBU5PnF9hv05mZGTw0EMPsX79emrVqsXYsWPPTR1cEHumKr6wpvxTFV/qHC513A4dOnDgwAGWL19Obm7uuW4ppYpDbp7hu42xbI5NJjEti8S0LE6kZXIiLZOUjBwARrQP5YVeTfBwu8J2qjFwZAOs/hi2zQMMNOlj3bRU6xr7xrSHdoSQ1rDyQ2g1Alwv8Vvtsa3ww1MQ1gmuf/HK6i0G2qK305AhQ5gxYwazZ89m4MCBgDWlcNWqVXF3d2fp0qUcPHjwH4/RqVMnpk+fDsDWrVsLXIbvbCgHBQWRlpZ27kJuxYoVCQkJYd68eQBkZmZy5swZevTowaRJkzhz5gzAua6b0NBQNmzYAPCPF4MvdQ5du3Zl5syZJCYmnndcsKZCGDp0qLbmVbH689BJbvnod56ZHcOCzUfZE5+GCDSpUZF+UTV5qntDvry7DWNvDr+ykM86bd0ANfE6+Lwr7PkZ2j4Ij22CW7+E2m3tv3FJxOqrTz4EW+cUvE9GitUv7+UPA74Al0uvLV3Syl6L3kHCw8NJTU2lZs2aBAcHA3D77bfTp08foqOjadGiBY0bN/7HYzz44IPcddddRERE0KJFC9q0aXPRPpUqVeK+++6jefPmhIaGnlvlCWDatGncf//9vPzyy7i7uzNr1ix69uzJpk2biI6OxsPDg169evGf//yHp59+mltvvZVp06bRpUuXS9Z0qXMIDw/nxRdf5LrrrsPV1ZWoqCimTJly7j2jR49m6NChl/vXqNRFkk5n8daPO5mx7jDVKnoyfmgUvSOCi2+R7IRd1oXTTd9YF1GrNoWb3oGIweDpd+XHbdjTOtaKt62bnwDE5e+vnT/AyQMw4ocSm6zMXjpNsbpss2fP5vvvv2fatGmX3Ef/zVRhcvMM36w9xNs/7eJ0Zg53XxvGY10b4Hs5491zMmH1J7DV9luri7s1J42rO7i4WQF8ZL21rektEH3P5bXcC7NtHsy689Kv3/A6tCvZeWzO0mmKVbF59NFHWbx4MYsWLXJ0KaoMycszxJ5MZ098Knvj09gTn8afh06yL+E07eoG8sot4TSodhmta2Ng90/w0/PW+PTa7cCrEuRlQ26WNc1AToYV6F3HQNRw8C2G0TkXCu8L9Q5ZK0MZAybv7y9Xj5L5zCugQa8uy/jx4x1dgirlsnPz2HUslZjYU8TEJrPlyCn2JaSRkf33OsZV/DxpUNWXx7s1pM/ldtOc2AM/joK9SyCwAdw+Bxp0K4EzsZNXMU5bXELsCnoR6Ql8ALgCnxtj3rjg9TrAJKAKkAQMM8bE2rZ/Z3ufOzDeGPPplRR6qVEgqvQpbd2BquRtPpzMvE3W8nrb4lLIzLFCvZKPO81r+tOubh0aVPOlflVf6lfxw9/nCu69yEiB5W9a0w+4+0CP16DNSHCzY+6acq7QoBcRV+AjoDsQC6wTkfnGmO35dhsHfGmMmSoiXYDXgeHAUaC9MSZTRHyBrbb3xl1OkV5eXiQmJhIYGKhhX8oZY0hMTMTLq4jLq6kyYc1fiUxYupff9pzAy92F5jX9Gd62DhG1KtEipBK1AryL5/9sXi58MwQOrrQWz+46xuEXOMsSe1r0bYC9xpi/AERkBnALkD/omwJP2h4vBeYBGGOy8u3jyRUO5wwJCSE2NpaEhIQrebu6yry8vAgJKeJ83arUMsbw254TTPh1L2sPJBHk68GoGxszrG2dy7uQejl+e8ea8fGWj62gV5fFnn+VmsDhfM9jgWsu2GczMACre6cf4CcigcaYRBGpBSwE6gPPFNSaF5GRwEiA2rVrX1SAu7s7YWFhdpSqlCopeXmGJTuO89HSvWyOPUWwvxdj+zRlSJvaFy/YUZwOrYFlb0DzQdDitpL7HCdmT9AX9HvXhZ2wTwMTRGQEsAI4AuQAGGMOAxEiUgOYJyKzjTHnzRNgjJkITARreOVlnYFSqkTl5OaxICaOT5btY/fxNGoFePN6/+b0b1kTT7cSvgkoPRnm3Gut6HTTuyW+EpOzsifoY4Fa+Z6HAOe1ym2t9P4Atr74AcaYUxfuIyLbgI5A6Zy3Vyl1TkZ2LrM2xDJxxT4OJ6XTsJovHwxpwU3Ng3FzvQo31RsDPzwJKUfg7p+uykpMzsqeoF8HNBCRMKyW+hDgvN+fRCQISDLG5AHPY43AQURCgERjTLqIVAY6AO8WY/1KqWIWn5rBrPWxTFl5gITUTCJrVeLl3uF0bVwVF5er2KLe9DVs+w66vAS1Whe+v7qkQoPeGJMjIo8AP2ENk5xkjNkmIq8A640x84HOwOsiYrC6bh62vb0J8I5tuwDjjDHFPMewUqqocnLzWLorgW/XHWbprnhy8wwd6gfyweAWtKtXhNFuqcfh55fAzQsqVLFGypz907caVA4D1wJi6MReWPSMNXnYtU9e/Lq6LGViCgSlVMnYf+I03647zJyNsSSkZhLk68mAVjUZ1KoW9av6Fv0DZt5pzfniHQBnTlh3jObn4Qe1r4HQa6HOtVCjhdVl80V3SD4ID/wB/jWLXkc5oFMgKKXOs/5AEp8u38eSHfG4ugjXN6rCrdG1uL5xVdyLq/999/9g+zxrbdVOz1hj4c8kwekEay73lKMQu84aNrlkrPUe9wpQqRYk7ITB0zXki4kGvVLlRF6eYemueD5dvo91B05Sycedx7o2YNg1talasZhvcMs6bS3kEdQI2j9ubXNxteZ+8a2CdesN0MI2A2paghX4B/+wborq8IS1NqsqFhr0Sjm5pJTTbPtjPq/uCGZ3/GlqVvJmTJ+mDG5dCx+PEoqA5W/CqUMwYpF9UxT4VrEmCAvvWzL1lHMa9Eo5kezcPHYcTWHT4WT+PJTMn4dOcmPyDJ5zn0H7CqN5cPBQekfUKLx7Zt3ncDTGuojq5gGuntYaqq4e1pqpYZ0u/d7j26z1VKOGQWiH4j1BdUU06JUqw7Jz84iJTWbl3kRW7ktk46GT5yYUq+rnSdsQTx7L+hGyYUy1P5CoZwo/aOI+WPi0tSiHiLVYdm7m+RdS2z0C3cZevIReXh4seMKa0bH7q8V2nqpoNOiVKmMOJ53hx63H+GPfCdbuT+JMVi4i0DS4IsPa1qFl7cpE1a5EsL8XsnI87E+GRr2QXYusKX6DGvzzB6z5r7VoxyPrwK/639tzcyD7NPzyKqyaALHrYeCk8y+YbpwCsWuh76fgU/hC9erq0KBXqozIyzNMXnmAt37cSWZOHvWqVGBAyxA61A/kmrBAKle4oC8864y1eHXdztDnA2uN1HWfw41vXvpD0pPhz6+g2YDzQx6s8e6u/nDTOGuVpvmPwX87Qv/PoH5XSIu3Rs+EdoTIIcV89qooNOiVKgMOJp7mmVkxrD2QRJfGVfn3zeHUCvD55zdtmGINZbzuOesGpfC+1t2mXV4Cz0uMkd841Wq1F7b8XfOBUD3CWkbvqwFw3bOQuBey06H3ezonTSmjQa9UKZaXZ5i+5iCvL96JqwhvDYxgUKuQwu9UzU6HP963Wtd12lvb2oyELbMg5ltofc/F78nNgTUTrfcERxZeXJWGcO8v1jDK5bbfEq4bVXjXkLrqNOiVKqWOJKfz3OwYft97go4NgnhzQAQ1Knnb9+aN0yDtOAz4/O9tIa2tVvi6zyH67otb3Tu+h5RYq2vGXh4+0Pdja3TN/hU6XUEppUGvVClzOOkMn//2F9+uP4yLCK/1a8ZtbWrbP99MTib8/p61YHZox7+3i1it+vmPWDcmhV7792vGWEMiA+pBgxsur2ARayhl1LDLe5+6ajTolSoldh1L5dPl+5i/OQ4Xgb4tavJY1waF98Vf6M+vIDUO+n50cau92QD432hY+9n5QX94LRzZAL3GgctVmIJYXVUa9Eo5kDGG9QdP8umyffyyMx4fD1dGtA/lnmvD7O+myS8ny2rNh7SButdf/LqHD7QcDqs+hpQ4qFjD2r76I/CqpCs4OSkNeqWKU9yfsG2uNSuj5wVfletAQF2MMcTEnmLRlqMs2nqUw0npVPZx58luDbmjXR1rmGROFnxzm3U3avOBUL+b9bgwm7+BU4eh9/uXHvkSfQ+snGCNyrn+BTh5EHYsgPaPgUeFYv3rUKWDBr1SxSUnE2bdBScPcPFqm2AQZjZ8h/GHw4g9mY6bi9ChfhCPXt+A3pHB5887s/xN2LXQamVv+86607TJzda6qaHXWhOEXSg321pEu0ZLa1z7pQSEQYMesH4ydHzaukFKXKz+e+WUNOiVKi6rP4aT+2HYHAi7DjJTITOFQ0ePM3VpDAOPf0C3XWNZFTKRx7tG0L1pNSr5FDDhV+x6+P1daHG7daPTX8usYZHb5sKf08C3OtSIsqYkyMsBk2tNAZyZYs3hfuNbhY9jb3MfTB8Im6bDxi8hvJ9OCezENOiVKg4pR2HFOGjUy+pmAVJd/Phw5TEm/5GIj0dtwtu/T+P1w3jf81NoObfgi57Z6TD3AfCrAT1ft+aSadDd+so6A7t/hK1zrN8aXNyslr2LG4greFa0umUa2jFqpl5Xa3Wnxc9Cbha0LeQGKVWmadArVRyWjLUC84bXMMYwb9MR/rNoJyfSMhkcXYtnbmhEoK8nVHkDFjwOKz8oeMz5r/8HiXtg+FyruyY/Dx9o1t/6KioXF2h9L/zvRajd3pqRUjktDXqliurwOoiZgenwJOtOVeLtmatYd+AkkSH+fHZHNC1qVfp735Z3wr6lVqCHdoSQfCu/HVxpjWWPvgfqdSn5uqNut/r/r3++5D9LOZSuGatUUeTlkTPxerKSjjDEczwxCXkEVPDguZ6NGNSqFi4uBfSVpyfDpx2tfvQHfrNa7plp8Klt7vYH/rj0XDRKXcI/rRmrd0YodQWMMaw/kMSMz17H7dgmXkgbhItXRd4aEMHvz13P4Na1Cw55AO9KMPALOBULPzxp3ZX688vWMMdbPtaQV8VOu26UugypGdnM+/MIX60+RNzx4yzz/C+HKjTjvvueI7xmpcIPcFatNtYY9l9ftcaub/zSWsxDV2RSJUCDXik77DyWwrRVB5n35xFOZ+XSrGZFZjX5jYD9KQTePh4uJ+TPuvZJ2L/cCvmghtBldPEXrhQa9EpdkjGGRVuOMWXlftYdOImnmwu9I2owvF0dIr2OI59Mty5oXumIFRdX6DcRFj8DnZ4B9yuY8kApO2jQK5W4z7oT1S8Yal0DtdpwONOHF+Zu4bc9J6gT6MOLvZowKNyPSgnrYNsM2PkDuPtA1zFF++yKwTD4q+I5D6UuQYNelW9HY+Cr/tbNSLlZ1mIdQJ6pzkAa8mhUB1r7pyI7foNfYwADbl5WH/tNj1krNylVymnQq/Lr4Er4erB1R+nIRezMqMTk2fPwP7GRnv6H6M12XHesAFcPa9GO656DsI7WY3smGFOqlNCgV+XT7p8wM+8g1y+EmOsn8/OGPD5bsR5/7zDG3tqbqIhgBKwhkBWCtP9clWka9KrciE/JYPqaQ1TeN4N67qUAABqOSURBVJdhx95kp6nDHUefJunrwwD0b1mTl25qak0TfFalWg6qVqnio0GvyoVjpzIYMnEV1yXP5Un3qezwjGRB43E8Ub0qYUEVqF/Vl2B/bbUr56RBr5xefEoGt322mh6p83jBfSo0uokmAyfRxN3L0aUpdVVo0CunFp+awZDPVtMo5Q+ed5kKjXvDoKngqt/6qvzQ73bltE6kZXLbZ2vwS97FBM+PkCoR0H+ihrwqd/Q7XjmlxLRMbvtsNZknj7DQ7z1cXf1h6Le6Jqoql+yavVJEeorILhHZKyKjCni9joj8IiIxIrJMREJs21uIyCoR2WZ7bXBxn4BSF0pMy+T2z9dwPPEki6p+gmf2KbhthnUXqlLlUKEtehFxBT4CugOxwDoRmW+M2Z5vt3HAl8aYqSLSBXgdGA6cAe4wxuwRkRrABhH5yRiTXOxnosoXY+B0Anj4WisvAfsS0pi26iCzN8SSk5vD73Vn4HdoCwz5GoIjHVywUo5jT9dNG2CvMeYvABGZAdwC5A/6psDZddGWAvMAjDG7z+5gjIkTkXigCqBBr+x3fBsc3WzNSZO0z/bnX5CVhnFxI6VyM37PasCcxDpslkZ0j2jIC56zCNq0GHr8HzTu5egzUMqh7An6msDhfM9jgWsu2GczMAD4AOgH+IlIoDEm8ewOItIG8AD2XfgBIjISGAlQu3bty6lfObPcHGu+dtv8M4grVK4DAXVJq96aTacDOLD/LxolbKGHy1xu8sjBIEhCQzixC1reYc3xrlQ5Z0/QF7RMzoXrDz4NTBCREcAK4AiQc+4AIsHANOBOY0zeRQczZiIwEaylBO2qXDm31OMw+244+Du0ugvaP0qSe3UWbT/B/E1xrN2aBECb0K7c2T4UGlaEY38iB1dac9hUbw43vWst16dUOWdP0McC+e8DDwHi8u9gjIkD+gOIiC8wwBhzyva8IrAQGG2MWV0cRSsnd+APmH0XZKRg+n7KIpfOzJ5/mN/27CInz1C/qi9P92hIn8ga1AnMN4om9FrrSyl1HnuCfh3QQETCsFrqQ4Db8u8gIkFAkq21/jwwybbdA5iLdaF2VnEWrpyQMbDyQ1jyb6gcyulbZ/Hsb7ks3LKRGv5e3NMxjFsia9Ik2A/RlrpSdis06I0xOSLyCPAT4ApMMsZsE5FXgPXGmPlAZ+B1ETFYXTcP295+K9AJCLR16wCMMMZsKt7TUGVaTibErodVH8GuhdD0FnZd8zoPzNzDoaQzjLqxMSM71r30YttKqX8kxpSuLvHo6Gizfv16R5ehSlJerjWKZv8Ka83Ug6sgJx1c3KH7K8x07c1L87fh7+3O+KFRXFM30NEVK1XqicgGY0x0Qa/pnbHq6kk/Cb+9ay2GnWEbYVuliTU6pu51pNdox0s/HWb2hi10qB/I+4OjqOKnC3woVVQa9Krk5WTC2s9gxduQcQrC+0GjXhDWCfyqcTwlg193xjNl8VZ2x6fyWJf6PN6tIa7aVaNUsdCgVyUnLw+2fQe//BuSD0G9rtD93+RVbcbm2GR+XRXPrzt3sy0uBYCQyt5MuasN1zWs4uDClXIuGvSqZBxaAz8+B3F/QrXmMHwup0M6MXHFX3y1egmJp7NwEWhVpzLP9mxE18bVaFjNV0fTKFUCNOhV8crNgd/GwfI3wS8Y+n5KbvNbmb3xCO/MWEZ8aibdmlSjT2QwnRpUOX/ZPqVUidCgV8XnVCzMuQ8OrYSIIXDTOFYczOA/4/9g57FUompX4pNhrWhVp7KjK1WqXNGgV8VjxwL4/hHIy4F+/2Vfjd68Mn07y3cnUCvAmwm3RXFT82DtmlHKATToVdFkp8NPL8L6L6BGFAz4gl/ifXls/O+4uggv9mrCHe3r4Onm6uhKlSq3NOjVlTu0BuY/as0U2f5RTJeX+GxlLK8vXk+zGv58dkc01f11AW6lHE2DXl2+9GRryOT6SVAxBIbNITP0ekbP3cqsDbHc1DyYcYMi8fbQVrxSpYEGvbKfMbBjPix6Fk7HQ9uH4foXSMx254HP17DuwEke79qAx7s20HlplCpFNOiVfU7FwsKnYfdiqB5hrcFaI4pdx1K5Z+ofJKRmMn5oFH0iazi6UqXUBTTo1T9LPQ6rJsC6LwBjLc13zYOk5cAnP+3ks9/2U8nbnZn3tyOyViVHV6uUKoAGvSrYqSPW3PAbpkBuFjQbAF1Gk+dfh9kbY3n7p10kpGbSL6omz9/YmKoV9aKrUqWVBr0638mD8Pt7sGk6mDzrxqeOT0FgPdbuT+KVr35n65EUompXYuLwVkTV1puflCrtNOjV39Z9DoufA3GBqGHQ4QmoXIeDiad5c/oGFm05RrC/Fx8MacHNkTX05ielyggNemWNpln2Bix/AxrcAL3fA/+aJJ3OYvyCbXy1+iBuLi482a0hIzvV1WGTSpUxGvTlXV4uLHrGurO1xe3Q50My8oTJy/bx8dK9nM7KYXDrWjzRrSHVtB9eqTJJg748y8mE70bC9nnQ4XHyuoxl7qY43vnfLuJOZdC1cVWeu7ExDav5ObpSpVQRaNCXV5mpMON2a83WHv/HqRYP8NS0DfyyM57mNf0Zd2sk7esFObpKpVQx0KAvj9ISYPpAOLYF+n7Ktqq9eHDC78QlpzOmT1PubBeqd7Yq5UQ06Mubvb/AvAchIwWGfsPs1HBe/HgllX08+Pb+djpXvFJOSIO+vMjJhCX/htUfQZUmZA2dzZg1wjdrN9OubiDjb4siyNfT0VUqpUqABn15EL8T5twDx7dCm5EcavUcj87ayebYUzxwXT2e7tEQN1cXR1eplCohGvTOzBjrJqj/jQYPX84M/JoPDtVl8ofr8HRz4b/DW3FDeHVHV6mUKmEa9M4qLw/mjoQts8ir15Xvar/I63OTSDrzFwNahvB0j0a6KIhS5YQGvbP6+SXYMov9zZ/ggYOd2bXtGG3CApjauynNavo7ujql1FWkQe+M1n4GqyawzL8vI9a1pnYAfDqsJTeEV9f5aZQqhzTonc2uHzGLn2WNWxvujR/IMzc05t6OYbo4t1LlmAa9M4n7k9xZI9hlQnk85xEm392Wjg2qOLoqpZSDadA7i+RDpE8dSFJ2BV72fYlvRnSlbhVfR1ellCoFNOjLijNJMPd+8K4MVRpD1aZQtQn41yI7/RRJn96Md8ZpPgr+kC/u7IO/t7ujK1ZKlRIa9GXF2omw53/gVwNivj23Oc+9Aqm5XgTkJvNto/d4dcggXHWeGqVUPnYFvYj0BD4AXIHPjTFvXPB6HWASUAVIAoYZY2Jtr/0ItAV+N8b0Lsbay4/sdCvoG/aE276F9GSSDm5h2W/LSTkYQz23eNyiRzOsz52OrlQpVQoVGvQi4gp8BHQHYoF1IjLfGLM9327jgC+NMVNFpAvwOjDc9trbgA9wf7FWXp5s/gbOJEL7RzmTlcPnKxP4dPlpsnNbMrxtf27pUp/KFTwcXaVSqpSyp0XfBthrjPkLQERmALcA+YO+KfCk7fFSYN7ZF4wxv4hI52KptjzKy4OVEzA1ophzog5vf72M4ymZ3NisOs/1bExoUAVHV6iUKuXsmcmqJnA43/NY27b8NgMDbI/7AX4iElj08hS7F0PSPmZ79OPp2TEE+3sz+4F2fDKslYa8Usou9gR9QVf2zAXPnwauE5E/geuAI0COvUWIyEgRWS8i6xMSEux9W7lg/hjPSffqjNoZxr3XhjH3ofZEhwY4uiylVBliT9DHArXyPQ8B4vLvYIyJM8b0N8ZEAS/atp2ytwhjzERjTLQxJrpKFb3B56ycQ2uRw6v48Ex3HurSiBdvaqJTGCilLps9Qb8OaCAiYSLiAQwB5uffQUSCROTssZ7HGoGjiiArJ4/NM/+PFONDcOf7+FePRhrySqkrUmjQG2NygEeAn4AdwExjzDYReUVEbrbt1hnYJSK7gWrAa2ffLyK/AbOAriISKyI3FPM5OJ2M7FxemryAFqkr2B86mJHdIx1dklKqDLNrHL0xZhGw6IJtL+d7PBuYfYn3dixKgeVNWmYOD0zbQLeD08HdlcgBzzq6JKVUGad3xpYSxhh+3HqMfy/YTmbqCab4rMC12a1QsYajS1NKlXEa9KXAocQzjJm/laW7EmgSXJHPm+3BbWM6tH/E0aUppZyABn1JO7gKjm6yWuYVa1p/+lYDF1cyc3L5bMVfjP91L24uwuhejRkRHYTbx/dAva5QLdzR1SulnIAGfUmK+xOm9oG87PO3iyuZ3lWJy3Dn5px0hnvm4OeShcvSdPg1z9qn36dXv16llFPSoC8pmakw+27wrQp3LoCs05ASR0r8QVZtiiE1/hBVPDJpFFYd/6AAcPcBd2/w8IGKIVD3ekefgVLKSWjQl5SFT8PJAzBiIQTWIyc3jy/3+fHeEiEzpzYPXFeX3tfXx8tdl/hTSpUsDfqSsOkbiJkBnZ+HOu3ZcPAko+dtZcfRFDo1rMK/bw4nTOepUUpdJRr0xe3EXlj4L6hzLabj0/zfD9v54vf9VK/oxce3t+TGZtX1Dlel1FWlQV+ccjJh9l3g5gH9J/LOkn188ft+hrWtzfM3NqGCp/51K6WuPk2e4vTzGDgWA0NnMG17NhOW7mVom1q8ekszbcUrpRzGnknNlD12LYY1n8A1D/Bjdgtenr+Nbk2qasgrpRxOg7447PoR5t4P1ZuzrsETPDZjEy1qVWL80Ja4uepfsVLKsTSFiiI7AxY/B98Mhkq1+avrf7nnqxhCKnvzxZ2t8fbQoZNKKcfTPvorlbDbuiHq+Ba45kGOthnF7RM34OnuytS72hCgi3UrpUoJDfrLZQz8Oc1qybt7w9BvOR7cmTu/WENqRg7f3t+WWgE+jq5SKaXO0aC/HDlZVl/8tu8grBP0m8iedF9GfLyS5DNZfHZnNOE1/B1dpVJKnUf76C/HjvlWyHd+HobPY22iJwM+WUlWbh7f3t+O9vWCHF2hUkpdRFv0l2PXYvAJgk7PsHBrPE9+u4mQAG+m3tVGu2uUUqWWBr29crNh78/QuDdfrDzE/y3cTsvalfn8jmgq64VXpVQppkFvr0OrIeMUM1Ob8erq7fQMr877Q1ro7JNKqVJPg95euxaTK+6M3VaNEe1Deal3U1xd9I5XpVTpp0FvD2PI2bGQVXnhtGoQwpg+TXVaA6VUmaGjbuxgEnbhduoAv5pW/Kdfcw15pVSZokFvh+3LZwLQqNMgHV2jlCpzNOgLkXQ6i6xtC9nnVo9BXdo6uhyllLpsGvSFeG/eSiLMLvwj++jFV6VUmaRB/w+W7YrnzLbFuIohqFVfR5ejlFJXRIP+Ek5n5vDi3K3c4rMZ4xcMwS0cXZJSSl0RDfpLGPe/XSQkp9CBGKRhT9CRNkqpMkqDvgAbDiYxZeUBXmyaiGvOaWh0o6NLUkqpK6ZBf4GE1Ewenv4nNSt5M7TSNnDztqYkVkqpMkqDPp/s3Dwenr6R5PQs/jusJR57f4J6XawFRpRSqozSoM/ntYU7WHsgiTf6RxDuehhSYqFRT0eXpZRSRaJBbzNnQyxTVh7g7g5h9I2qac09j0BDDXqlVNlmV9CLSE8R2SUie0VkVAGv1xGRX0QkRkSWiUhIvtfuFJE9tq87i7P44rL1yClemLuFtnUDeL5XY2vjrsVQsxX4VnVscUopVUSFBr2IuAIfATcCTYGhItL0gt3GAV8aYyKAV4DXbe8NAMYA1wBtgDEiUrn4yi+6pNNZ3D9tA4EVPJhwW0vcXV0g5SjEbdTRNkopp2BPi74NsNcY85cxJguYAdxywT5NgV9sj5fme/0G4GdjTJIx5iTwM1Bq+kJycvN45OuNJKRl8untLQhK3grL34Zvhlg7aNArpZyAPfPR1wQO53sei9VCz28zMAD4AOgH+IlI4CXeW/PCDxCRkcBIgNq1a9tbe5G9O381IQe+483ah6j19QOQkQwIBEfCDa9D1Qt/cVFKqbLHnqAv6JZQc8Hzp4EJIjICWAEcAXLsfC/GmInARIDo6OiLXi8JP8/5nHtixhLongppwdD4JmsoZd3OUCHoapSglFJXhT1BHwvUyvc8BIjLv4MxJg7oDyAivsAAY8wpEYkFOl/w3mVFqLfo0pM5/PVjdD/8PYe8GlBp2Pe4hrTUKQ6UUk7Lnj76dUADEQkTEQ9gCDA//w4iEiQiZ4/1PDDJ9vgnoIeIVLZdhO1h2+YY+5aSOb4twYcWMKvC7VR98ndca7XSkFdKObVCg94YkwM8ghXQO4CZxphtIvKKiNxs260zsEtEdgPVgNds700CXsX6YbEOeMW27erKOgOLnoVpfYk7Izzh+xY9Hv4ALy+vq16KUkpdbWLMVekSt1t0dLRZv3598R0wIwWm9IJjW5jhchMfu97ONw93oWYlndZAKeU8RGSDMSa6oNfs6aMvu/JyYc69mOPbednnJeadbs7M+9ppyCulyhXnngLh55dhz098FfAIM0415b/DW9EkuKKjq1JKqavKeYN+w1RYNYHc1iN55Vhb7mwXSvv6OmxSKVX+OGfQ7/8NFj4F9bqyM3IU2bmGyFqVHF2VUko5hPMFfeI+mDkcAurBoMlsP3YGgPAa2mWjlCqfnCvo05Nt89QI3DYDvPzZfjQFHw9X6gRWcHR1SinlEM4z6iY3B2aNgKT9cMf3EFAXgO1xKTSu7oeri94UpZQqn5ynRZ98EI5vg97vQWgHAIwxbD+aQlPttlFKlWPO06IPrAePrAPvvy+6xp5MJzUjh6bB/g4sTCmlHMt5WvRwXsgDbItLAdAWvVKqXHOuoL/A9qMpuAg0qubn6FKUUsphnDvo41KoV8UXbw9XR5eilFIO49RBv0MvxCqllPMGffKZLI4kp9NU57ZRSpVzThv024/qhVillAJnDnrbiBudrVIpVd45ddBXq+hJkK+no0tRSimHct6gP5pCeA29UUoppZwy6DOyc9kbn6YXYpVSCicN+r3xaeTkGb0Qq5RSOGnQn70Qqy16pZRy0qDfFneKCh6u1A7wcXQpSinlcE4Z9NuPptAkuCIuOge9Uko5X9Dn5Rl2HE3V/nmllLJxuqA/fPIMaZk5ukasUkrZOF3Q/30hVsfQK6UUOGPQH03B1UVoUM3X0aUopVSp4HRBvy0uhfpVfPFy1znolVIKnDDot8fpHPRKKZWfUwV9Ylomx1Iy9EYppZTKx6mCfsfRVAAdcaOUUvk4VdBvP3oK0DnolVIqP+cK+rgUavh7UbmCh6NLUUqpUsOpgn6bXohVSqmL2BX0ItJTRHaJyF4RGVXA67VFZKmI/CkiMSLSy7bdQ0Qmi8gWEdksIp2Luf5zMrJz2Zegc9ArpdSFCg16EXEFPgJuBJoCQ0Wk6QW7jQZmGmOigCHAx7bt9wEYY5oD3YF3RKREfotIzcihd0QN2oQFlsThlVKqzHKzY582wF5jzF8AIjIDuAXYnm8fA5xtSvsDcbbHTYFfAIwx8SKSDEQDa4te+vmq+Hny4dCo4j6sUkqVefa0rmsCh/M9j7Vty28sMExEYoFFwKO27ZuBW0TETUTCgFZArQs/QERGish6EVmfkJBwmaeglFLqn9gT9AVN6m4ueD4UmGKMCQF6AdNsXTSTsH4wrAfeB1YCORcdzJiJxphoY0x0lSpVLqd+pZRShbCn6yaW81vhIfzdNXPWPUBPAGPMKhHxAoKMMfHAk2d3EpGVwJ4iVayUUuqy2NOiXwc0EJEwEfHAutg6/4J9DgFdAUSkCeAFJIiIj4hUsG3vDuQYY7ajlFLqqim0RW+MyRGRR4CfAFdgkjFmm4i8Aqw3xswH/gV8JiJPYnXrjDDGGBGpCvwkInnAEWB4iZ2JUkqpAokxF3a3O1Z0dLRZv369o8tQSqkyRUQ2GGOiC3rNqe6MVUopdTENeqWUcnKlrutGRBKAg0U4RBBwopjKKUv0vMsXPe/yxZ7zrmOMKXB8eqkL+qISkfWX6qdyZnre5Yued/lS1PPWrhullHJyGvRKKeXknDHoJzq6AAfR8y5f9LzLlyKdt9P10SullDqfM7bolVJK5aNBr5RSTs5pgr6w5Q6diYhMEpF4Edmab1uAiPwsIntsf1Z2ZI3FTURq2Zar3CEi20Tkcdt2Zz9vLxFZa1uKc5uI/Nu2PUxE1tjO+1vbhINOR0RcbUuU/mB7Xl7O+4BtCdZNIrLetu2Kv9edIujtXO7QmUzBNi10PqOAX4wxDbBW9XK2H3Y5wL+MMU2AtsDDtn9jZz/vTKCLMSYSaAH0FJG2wJvAe7bzPok1VbgzehzYke95eTlvgOuNMS3yjZ+/4u91pwh68i13aIzJAs4ud+iUjDErgKQLNt8CTLU9ngr0vapFlTBjzFFjzEbb41Ss//w1cf7zNsaYNNtTd9uXAboAs23bne68AUQkBLgJ+Nz2XCgH5/0Prvh73VmC3p7lDp1dNWPMUbBCEajq4HpKjIiEAlHAGsrBedu6LzYB8cDPwD4g2RhzdrU2Z/1+fx94FsizPQ+kfJw3WD/M/yciG0RkpG3bFX+v27PCVFlgz3KHygmIiC8wB3jCGJNiNfKcmzEmF2ghIpWAuUCTgna7ulWVLBHpDcQbYzaISOezmwvY1anOO58Oxpg425oeP4vIzqIczFla9PYsd+jsjotIMIDtz3gH11PsRMQdK+SnG2O+s212+vM+yxiTDCzDukZRSUTONtSc8fu9A3CziBzA6ortgtXCd/bzBsAYE2f7Mx7rh3sbivC97ixBb89yh85uPnCn7fGdwPcOrKXY2fpnvwB2GGPezfeSs593FVtLHhHxBrphXZ9YCgy07eZ0522Med4YE2KMCcX6//yrMeZ2nPy8AUSkgoj4nX0M9AC2UoTvdae5M1ZEemH9xD+73OFrDi6pxIjIN0BnrKlLjwNjgHnATKA21hq+g4wxF16wLbNE5FrgN2ALf/fZvoDVT+/M5x2BdeHNFathNtMY84qI1MVq6QYAfwLDjDGZjqu05Ni6bp42xvQuD+dtO8e5tqduwNfGmNdEJJAr/F53mqBXSilVMGfpulFKKXUJGvRKKeXkNOiVUsrJadArpZST06BXSiknp0GvlFJOToNeKaWc3P8Div7jxjT6WXUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
    "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
    "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
